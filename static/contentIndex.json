{"Biography":{"title":"Biography","links":["Studies/SMERM/SMERM","Studies/PhD/PhD"],"tags":[],"content":"Luca Spanedda (1995) is an Electroacoustic Music composer and performer\nspecializing in computer music. His work explores the dynamic intersections between humans, cybernetics, and acoustic spaces.\nHe began his academic studies in Electronic Music at the Santa Cecilia Conservatory in Rome (SMERM), studying electroacoustic music composition under masters Michelangelo Lupone and Nicola Bernardini. In 2023, he graduated cum laude with a Master’s degree in Electronic Music, presenting a thesis on “Complex Adaptive Systems for Performance in Live Electronics,” supervised by Giuseppe Silvi, with co-supervisors Agostino Di Scipio and Dario Sanfilippo.\nHis work includes live electronic pieces, acousmatic music, and sound installations.\nHe is currently enrolled in a PhD program in Artistic Research in Music and Musical Aesthetics at the Conservatory Alfredo Casella in L’Aquila (IT)."},"Blog":{"title":"Blog","links":["Posts/Digital-Reverberation---a-tutorial-in-Faust","Posts/Exploring-Pseudo-Random-and-Stochastic-Signals-in-Digital-Sound-Synthesis","Posts/About-this-filters-business---a-tutorial-on-Digital-Filters-in-Faust"],"tags":[],"content":"Digital Reverberation - a tutorial in Faust\nExploring Pseudo-Random and Stochastic Signals in Digital Sound Synthesis\nAbout this filters business - a tutorial on Digital Filters in Faust"},"CV":{"title":"CV","links":[],"tags":[],"content":""},"Compositions":{"title":"Compositions","links":[],"tags":[],"content":"\nLuca Spanedda · WKR (Installation, excerpt) (Luca Spanedda &amp; Dario Sanfilippo) @ Infiniti Possibili [2024]"},"Contact":{"title":"Contact","links":[],"tags":[],"content":"Mail: lucaspanedda1995@gmail.com"},"Links":{"title":"Links","links":[],"tags":[],"content":"\n\n                  \n                  Github \n                  \n                \n\ngithub.com/LucaSpanedda\n\n\n\n\n                  \n                  Soundcloud \n                  \n                \n\nsoundcloud.com/luca-spanedda-1995\n\n\n\n\n                  \n                  Instagram \n                  \n                \n\nwww.instagram.com/luca_spanedda/\n\n\n\n\n                  \n                  Youtube \n                  \n                \n\nwww.youtube.com/channel/UCRCkVPYRcgo84G8W_uJZuaw\n\n\n\n\n                  \n                  Academia \n                  \n                \n\nconservatoriosantacecilia.academia.edu/LucaSpanedda\n\n"},"Posts/About-this-filters-business---a-tutorial-on-Digital-Filters-in-Faust":{"title":"About this filters business - a tutorial on Digital Filters in Faust","links":[],"tags":[],"content":"Preludes to Filter Syntax in Faust\nConstructing a delay line\nIn FAUST the _ represent a signal input.\nA function with one input that goes directly to the output is written as follows:\nimport(&quot;stdfaust.lib&quot;);\n\n// signal input - output\n//process = _;\n\nwhere process is the main function in Faust (the compiler’s output function).\nAnd import(&quot;stdfaust.lib&quot;); is the function for import the Standard Faust Libraries.\nFaust provides us with three different syntaxes to express a delay line:\n\n&#039; - is used to express a one sample delay. Time expressions can be chained, so the output signal of this program\n\n// signal in delay (&#039; = mem), (mem = Z^(-1)) \n //process = _&#039;&#039;; \n\nwill produce a delayed signal of two samples.\n\nmem - indicates a 1 sample delay. You can use the “mem” successively add delay samples, so the output signal of this program\n\n// signal in delay (&#039; = mem), (mem = Z^(-1)) \n//process = _ : mem : mem : _; \n\nwill produce a delayed signal of two samples.\nThese last two programs produce the same result.\n@ - indicates a number of variable delay samples, so for example a signal with 192000 samples of delay is written like:\n // signal in delay (@192000 = 192000 samples of delay) \n //process = _ @ 192000; \n\n\nDirac impulse\nNow, another element that we can introduce through the filter syntax is the Dirac impulse, which represents our minimum DSP unit, namely the single sample\nby putting a number 1 and subtracting the same value from it\nbut doing it at a delayed sample.\nExample:\n// Dirac Impulse with delay lines - Impulse at Compile Time  \n dirac0 = 1 - 1&#039;;  \n //process = dirac0; \n\nor something like that using functional syntax:\n// Dirac Impulse with delay lines - Impulse at Compile Time  \n dirac1(x) = x - x&#039;;  \n //process = dirac1(1); \n\n\nMethods for Implementing Recursive Circuits in the Faust Language\nNow we will illustrate three main methods for Implementing Recursive Circuits in FAUST Language:\n\nWriting the code line with internal recursion:\nin this way tilde ~ operator sends the signal\noutput to itself, to the first available input\ncreating a feedback circuit.\n\nOne way to force the operator to point to a certain point\nin the code, is to put parentheses (), in this way ~\nwill point to the input before the parenthesis.\nIn this program, the input is summed with itself delayed by one sample and multiplied by 0.5:\n// dirac in feedback in sin \n//process = (1 - 1&#039;) * 1000 : (_ + _) ~ _ * (0.9999) : sin;\n\n\nUsing the with construction with{};:\nIt can be used to create a local enviroment.\nYou can define a function in which are passed\nthe various arguments of the function that control\nthe parameters of the code,\nand say that that function is equal to\nexit from the with, with ~ _.\nYou can find an exhaustive explanation of with construction here\n\nExample:\n // with environment example (dirac in feedback in sin) \n //where out ~ _ returns to itself. \n function_with(input1, input2) = out ~ _ : sin \n     \twith{   \n      \t\tsection1 = (1 - 1&#039;) * input1; \n      \t\tsection2(argument1) = (argument1 * input2) + section1; \n      \t\tout = section2; \n      \t}; \n //process = function_with(1000, 0.9999); \n\nMoreover, with in Faust allows declaring variables\nthat are not pointed to from outside the code but only\nfrom the belonging function; in this case\nthe function to which with belongs is “function_with”.\n\n\nA third method is to use the letrec environment.\nwith this method we can write a signal\nrecursively, similar to how\nrecurrence equations are written.\n// letrec function  \n function_letrec = sin(y) \n // letrec definition  \n \tletrec {  \n  \t\t&#039;y = dirac * damp + amp * y;  \n  \t}  \n  \t// inside the letrec function  \n     with {  \n         dirac = (1 - 1&#039;); \n         damp = 1000; \n         amp = 0.9999; \n     };  \n//process = function_letrec &lt;: si.bus(2);\n\n\n\n\nConcluding this chapter on filter syntax in FAUST, we need to introduce a fundamental concept\nthat will help us gain a more comprehensive understanding of digital filters:\nthe relationship between milliseconds and samples → sampling frequency.\nMilliseconds - Samples and the importance of the sampling frequency\nDigital filters differ from analog filters for one particular reason: the Analog-to-Digital (AD)\nconversion system involves discretizing a continuous physical phenomenon into a sampled numerical one.\nUnderstanding the relationship between time and samples helps us in reasoning and practical\napplications of digital filters. These filters indeed entail spectral changes\n(when observed in the frequency domain) and involve temporal integration\nchanges (when observed in the time domain).\nThis brief preamble will be explained further in the chapter on the bilinear transform.\nFor now, let’s focus on small examples of converting between milliseconds and samples.\nConversion from Milliseconds to Samples\nThis program takes input time expressed in milliseconds\nand returns the value in samples.\n// milliseconds to samples conversion \nmilliseconds = 10; \nmsec2samps(msec) = msec * (ma.SR/1000); \n//process = msec2samps(milliseconds);\n\nThrough ma.SR, we use the current sampling frequency of\nthe machine we are using.\nFor example, if we have a sampling frequency\nof 96000 samples per second,\nit means that 1000ms (1 second) is represented\nby 96000 parts, and therefore a single unit\nof time like 1ms corresponds digitally to 96 samples.\nFor this reason, we divide the sampling frequency\nby 1000ms, resulting in a total number of samples\nthat corresponds to 1ms in the digital world at\na certain sampling frequency.\nAnd then we multiply the result of this operation\nby the total number of milliseconds we want to obtain as\na representation in samples.\nIf we multiply by 100 we will have\n9600 samples every 100ms at a sampling frequency\nof 96000 samples per second.\nConversion from Samples to Milliseconds\nFunction for Conversion from Samples to Milliseconds:\nwe input a total number of samples,\nof which we need to know the overall duration\nin milliseconds based on our sampling frequency.\nWe know that a sampling frequency\ncorresponds to a set of values that express\ntogether the duration of 1 second (1000 ms).\nIt means, for example,\nthat at a sampling frequency of 48,000\nsamples per second,\n1000 milliseconds are represented by 48,000 parts.\nSo if we divide our 1000ms. /\ninto the 48,000 parts which are the samples of our system,\nwe would get the duration in milliseconds of a single sample\nat that sampling frequency,\nin this case therefore:\n1000 / 48,000 = 0.02ms.\nAnd so the duration in milliseconds of a single sample at 48,000\nsamples per second, is 0.02 milliseconds.\nIf we multiply the obtained number *\na total number of samples, we will get the time in milliseconds\nof those samples for that sampling frequency used.\nObviously, as can be deduced from the considerations,\nas the sampling frequency increases,\nthe temporal duration of a single sample decreases,\nand thus a greater definition.\nPhase Alignment of Feedback\nWe need to spend a few words about the implementation of a delay line in feedback in the digital world.\nIn the following program, we have a Dirac impulse that is summed by itselfs delayed by 2 samples.\n// dirac delayed \n//process = (_ + (1 - 1&#039;)) ~ _ @2; \n\nWe expect these values to appear in the first 10 samples:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnth samplevalue01102130415061708190\nHowever, the results of the data plot are as follows:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nnth samplevalue01102031405061708091\nThere’s something wrong. With each feedback cycle, it’s being delayed by one extra sample!\nThat’s because in the digital domain, the feedback of a\ndelay line, when applied, costs by default one sample delay.\n‘Feedback = 1 Sample’\nSo one must consider that the number of delay samples equals the number of samples minus 1:\n// dirac delayed + phase alignment \ndelSampsDirac0 = 2; \n//process = (_ + (1 - 1&#039;)) ~ _@(delSampsDirac0 - 1);\n\nIn some application scenarios later on, we’ll need a one-sample delay even at the input signal.\nIn this case, simply concatenating a delay line in series will suffice.\n// dirac delayed + phase alignment (final) \ndelSampsDirac1 = 2; \n//process = (_ + (1 - 1&#039;)) ~ _@(delSampsDirac1 - 1) : mem;\n\n\nDigital Filters\nONEZERO FILTER (1st Order FIR)\n_ represents the input signal, (_ denotes the signal)\nit is then split into two parallel paths &lt;:\none delayed by one sample _&#039; (&#039; denotes one sample delay)\nand one without delay, _ (, denotes transition to the second path)\nthey are then summed into a single signal :&gt; _ ;\nthe delayed signal has a feedforward amplitude control * feedforward\nthere is a general amplitude control * outgain\non the output function onezeroout\n// onezero, g = give amplitude 0 to +/- 1 (open - close) to the delayed signal  \noz(b1) = _ &lt;: (_ : mem * b1), _ :&gt; +;  \n//process = oz; \n\nONEPOLE FILTER (1st Order IIR)\n+ ~ is the summation, and the feedback of the arguments inside parentheses ()_ represents the input signal, (_ denotes the signal) delayed by one sample _ (automatically in the feedback) which enters : into the gain control of the feedback * 1-feedback the same feedback controls the input amplification of the signal not injected into the feedback there is a general amplitude control * outgain on the output function onezeroout\n// onepole, g = give amplitude 0 to +/- 1 (open - close) to the delayed signal  \nop(b1) = _ * (1 - abs(b1)) : + ~ * (b1); \n//process = op; \n\nand OPF with Frequency Cut transfer functions:\n\n(1)\n\n// onepole with frequency cut formula (chamberlin), fc = Hz \nlp1p(fc) = _ * g : + ~ * (1 - g) \n    with{ \n        k(x) = x / (1.0 + x); \n        g = tan(fc * ma.PI / SR) : k; \n    }; \n//process = lp1p; \n\n\n(2)\n\nlp1p2(fc) = _ * (1 - b1) : + ~ * (b1) \n      with { \n           b1 = exp((fc * ma.PI / ma.SR) * -1); \n      }; \n//process = lp1p2; \n\nsame OPF with Formulae expressed in Seconds (1 / FC)\n\n(3)\n\n// onepole in seconds or smooth function \nopsec(sec) = _ * g : + ~ * (1 - g) \n    with{ \n        k(x) = x / (1.0 + x); \n        g = tan((1 / sec) * ma.PI / ma.SR) : k; \n    }; \n//process = opsec; \n\n\nFEEDFORWARD COMB FILTER (Nth Order FIR)\n_ represents the input signal, (_ denotes the signal) it is then split into two parallel paths &lt;: one delayed by @(delaysamples) samples (thus value to be passed externally) and one without delay, _ (, denotes transition to the second path) they are then summed into a single signal :&gt; _ ;\nthe delayed signal has a feedforward amplitude control * feedforward\nthere is a general amplitude control * outgain on the output function onezeroout\n// feedforward comb filter, (t, g) = delay time in samples, filter gain 0-1  \nffcf(t, g) = _ &lt;: ((_ @ (t)) * g), _ :&gt; +;  \n//process = (1000, 0.9, _) : ffcf; \n\nFEEDBACK COMB FILTER (Nth Order IIR)\n+ ~ is the summation, and the feedback of the arguments inside parentheses () _ represents the input signal, (_ denotes the signal) delayed by @(delaysamples) samples (thus value to be passed externally) which enters : into the gain control of the feedback, * feedback\nIn the feedback, one sample of delay is already present by default, hence delaysamples-1.\nthere is a general amplitude control * outgain on the output function combfeedbout\n// feedback comb filter, (t, g) = give: delay time in samples, feedback gain 0-1 \nfbcf(t, g) = _ : (+  @(t - 1) ~ *(g)) : mem; \n//process = (1000, 0.9, _) : fbcf; \n\nLowpass FEEDBACK COMB FILTER (Nth Order IIR)\nsimilar to the comb filter, but within the feedback, following the feedback enters the signal : into the onepole. The onepole is a lowpass where the cutoff frequency can be controlled between 0. and 1. In the feedback, one sample of delay is already present by default, hence delaysamples-1.\n// lowpass feedback comb filter, (t, g) = give: delay time in samples, g gain 0-1, Freq cut (HZ) \nlbcf(t, g, fc) = _ : (+  @(t - 1) ~ (lp1p(fc) * (g))) : mem; \n//process = (1000, 0.9, 10000, _) : lbcf; \n\n\nALLPASS FILTER\nfrom the sum of a comb IIR and a comb FIR in opposition of phase, emerge a recursive delay unit that preserve the phase of the input signal. (+ transitions : to a cable _ and a split &lt;: then @delay and gain, in feedback ~ to the initial sum. filtergain controls the amplitude of the two gain states, which in the filter are the same value but positive and negative, one side * -filtergain and one side * +filtergain. In the feedback, one sample of delay is already present by default, hence delaysamples-1. To maintain the delay threshold of the value delaysamples, a mem delay (of the subtracted sample) is added at the end.\n// allpass filter, (t, g) = give: delay in samples, feedback gain 0-1 \napf(t, g) = _ : (+ : _ &lt;: @(t  - 1), *(g))~ *(-g) : mem, _ : + : _; \n//process = (1000, 0.9, _) : apf; \n\nMODULATED ALLPASS FILTER\nAllpass Filter with Time-Variant delay\n// Modulated Allpass filter \nmodapf(delsamples, samplesmod, freqmod, apcoeff) = ( + : _ &lt;:  \n    delayMod(delsamples, samplesmod, freqmod), \n    * (apcoeff))~ * (-apcoeff) : mem, _ : + : _ \n    with{ \n        delayMod(samples, samplesMod, freqMod, x) = delay \n        with{ \n            unipolarMod(f, samples) = ((os.osc(f) + 1) / 2) * samples; \n            delay = x : de.fdelay(samples, samples - unipolarMod(freqMod, samplesMod)); \n        }; \n    }; \n//process = _ &lt;: modapf(1100, 800, .12, .99), modapf(1000, 900, .12, .99); \n\n\nSTATE VARIABLE FILTER (SVF)\nState variable filters are second-order RC active filters consisting of two identical op-amp\nintegrators with each one acting as a first-order, single-pole low pass filter,\na summing amplifier around which we can set the filters gain and its damping feedback network.\nThe output signals from all three op-amp stages are fed back to the input\nallowing us to define the state of the circuit.\nThe state variable filter is a type of multiple-feedback filter circuit\nthat can produce all three filter responses, Low Pass, High Pass and Band Pass\nsimultaneously from the same single active filter design, and derivation\nlike Notch, Peak, Allpass…\nRobert Bristow Johnson’s SVF Biquad\nThis filter transfer functions were derived from analog prototypes (that\nare shown below for each EQ filter type) and had been digitized using the\nBilinear Transform by Robert Bristow-Johnson: webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html\n// Robert Bristow-Johnson&#039;s Biquad Filter - Direct Form 1 \n// webaudio.github.io/Audio-EQ-Cookbook/audio-eq-cookbook.html \nbiquad(i, cf, q) = _ : coefficients(i) : biquadFilter \n     with{ \n         biquadFilter(a0, a1, a2, b1, b2) = biquadFilter \n             with{ \n                 biquadFilter =  _ &lt;: _, (mem  &lt;: (_, mem)) : (_ * a0, _ * a1, _ * a2) :&gt; _ :  \n                                 ((_, _) :&gt; _) ~ (_ &lt;: (_, mem) : (_ * -b1, _ * -b2) :&gt; _); \n             }; \n  \n         // Angular Frequency formula \n         omega(x) = (2 * ma.PI * x) / ma.SR; \n         // Angular Frequency in the sine domain \n         sn(x) = sin(omega(x)); \n         // Angular Frequency in the cosine domain \n         cs(x) = cos(omega(x));  \n         // Alpha \n         alpha(cf0, q0) = sin(omega(cf0)) / (2 * q0); \n  \n         // Robert Bristow-Johnson&#039;s Biquad Filter - Coefficents \n         // Lowpass Filter \n         coefficients(0) = a0, a1, a2, b1, b2, _ \n         with{ \n             b0 = (1 + alpha(cf, q)); \n             a0 = ((1 - cs(cf)) / 2) / b0; \n             a1 = (1 - cs(cf)) / b0; \n             a2 = ((1 - cs(cf)) / 2) / b0; \n             b1 = (-2 * cs(cf)) / b0; \n             b2 = (1 - alpha(cf, q)) / b0; \n         }; \n         // Highpass filter \n         coefficients(1) = a0, a1, a2, b1, b2, _ \n         with{ \n             b0 = (1 + alpha(cf, q)); \n             a0 = ((1 + cs(cf)) / 2) / b0; \n             a1 = (-1 * (1 + cs(cf))) / b0; \n             a2 = ((1 + cs(cf)) / 2) / b0; \n             b1 = (-2 * cs(cf)) / b0; \n             b2 = (1 - alpha(cf, q)) / b0; \n         }; \n         // Bandpass Filter \n         coefficients(2) = a0, a1, a2, b1, b2, _ \n         with{ \n             b0 = 1 + alpha(cf, q); \n             a0 = alpha(cf, q) / b0; \n             a1 = 0; \n             a2 = - alpha(cf, q) / b0; \n             b1 = (-2 * cs(cf)) / b0; \n             b2 = (1 - alpha(cf, q)) / b0; \n         }; \n         // Notch filter \n         coefficients(3) = a0, a1, a2, b1, b2, _ \n         with{ \n             b0 = 1 + alpha(cf, q); \n             a0 = 1 / b0; \n             a1 = (-2 * cs(cf)) / b0; \n             a2 = 1 / b0; \n             b1 = (-2 * cs(cf)) / b0; \n             b2 = (1 - alpha(cf, q)) / b0; \n         }; \n         // Peaking EQ filter \n         coefficients(4) = a0, a1, a2, b1, b2, _ \n         with{ \n             A = 10; \n             b0 = 1 + (alpha(cf, q) / A); \n             a0 = (1 + (alpha(cf, q) * A)) / b0; \n             a1 = (-2 * cs(cf)) / b0; \n             a2 = (1 - (alpha(cf, q) * A)) / b0; \n             b1 = (-2 * cs(cf)) / b0; \n             b2 = (1 - (alpha(cf, q) / A)) / b0; \n         }; \n         // Low Shelf Filter \n         coefficients(5) = a0, a1, a2, b1, b2, _ \n         with{ \n             //dbGain 20; \n             A  = pow(10, -20 /40); \n             beta = sqrt(A + A); \n             b0 = (A + 1) + (A - 1) * cs(cf) + beta * alpha(cf, q); \n             a0 = (A * ((A + 1) - (A - 1) * cs(cf) + beta * alpha(cf, q))) /b0; \n             a1 = (2 * A * ((A - 1) - (A + 1) * cs(cf))) / b0; \n             a2 = (A * ((A + 1) - (A - 1) * cs(cf) - beta * alpha(cf, q))) /b0; \n             b1 = (-2 * ((A - 1) + (A + 1) * cs(cf))) / b0; \n             b2 = ((A + 1) + (A - 1) * cs(cf) - beta * alpha(cf, q)) / b0; \n         }; \n         // High Shelf Filter \n         coefficients(6) = a0, a1, a2, b1, b2, _ \n         with{ \n             //dbGain 20; \n             A  = pow(10, -20 /40); \n             beta = sqrt(A + A); \n             b0 = (A + 1) - (A - 1) * cs(cf) + beta * alpha(cf, q); \n             a0 = (A * ((A + 1) + (A - 1) * cs(cf) + beta * alpha(cf, q))) /b0; \n             a1 = (2 * A * ((A - 1) + (A + 1) * cs(cf))) / b0; \n             a2 = (A * ((A + 1) + (A - 1) * cs(cf) - beta * alpha(cf, q))) /b0; \n             b1 = (2 * ((A - 1) - (A + 1) * cs(cf))) / b0; \n             b2 = ((A + 1) - (A - 1) * cs(cf) - beta * alpha(cf, q)) / b0; \n         }; \n}; \n//process = (1000, 1, _) : biquad(0); \n\n\nONEPOLE Topology Preserving Transforms (TPT)\nTPT version of the One-Pole Filter by Vadim Zavalishin\nreference: www.native-instruments.de/fileadmin/redaktion_upload/pdf/KeepTopology.pdf\nthe topology-preserving transform approach, can be considered as\na generalization of bilinear transform, zero-delay feedback and trapezoidal integration methods. This results in digital filters having nice amplitude and phase\nresponses, nice time-varying behavior and plenty of options for nonlinearities\n// Vadim Zavalishin&#039;s Onepole TPT Filter (Topology Preserving Transform)  \nonePoleTPT(cf, x) = loop ~ _ : ! , si.bus(3) \n     with { \n         g = tan(cf * PI * ma.T); \n         G = g / (1.0 + g); \n         loop(s) = u , lp , hp , ap \n             with { \n             v = (x - s) * G; u = v + lp; lp = v + s; hp = x - lp; ap = lp - hp; \n             }; \n     }; \n//process = onePoleTPT; \n  \n// Lowpass and Highpass TPT \nLPTPT(cf, x) = onePoleTPT(cf, x) : (_ , ! , !); \nHPTPT(cf, x) = onePoleTPT(cf, x) : (! , _ , !); \n  \n// Allpass TPT \nAPTPT(cf, x) = onePoleTPT(cf, x) : (!, !, _); \n\nVadim Zavalishin’s SVF Topology Preserving Transform\n// Vadim Zavalishin&#039;s SVF TPT filter (Topology Preserving Transform) \nSVFTPT(Q, cf, x) = loop ~ si.bus(2) : (! , ! , _ , _ , _ , _ , _) \n     with { \n         g = tan(cf * ma.PI * ma.T); \n         R = 1.0 / (2.0 * Q); \n         G1 = 1.0 / (1.0 + 2.0 * R * g + g * g); \n         G2 = 2.0 * R + g; \n         loop(s1, s2) = u1 , u2 , lp , hp , bp * 2.0 * R , x - bp * 4.0 * R , bp \n             with { \n                 hp = (x - s1 * G2 - s2) * G1; \n                 v1 = hp * g; \n                 bp = s1 + v1; \n                 v2 = bp * g; \n                 lp = s2 + v2; \n                 u1 = v1 + bp; \n                 u2 = v2 + lp; \n             }; \n     }; \n  \n// HP - LP SVF  \nLPSVFTPT(Q, cf, x) = SVFTPT(Q, cf, x) : (_ , ! , ! , ! , !); \nHPSVFTPT(Q, cf, x) = SVFTPT(Q, cf, x) : (! , _ , ! , ! , !); \n  \n// Normalized Bandpass SVF  \nBPSVFTPT(Q, cf, x) = SVFTPT(Q, cf, x) : (! , ! , _ , ! , !); \n  \nNotchSVFTPT(Q, cf, x) = x - BPSVF(Q, cf, x); \nAPSVFTPT(Q, cf, x) = SVFTPT(Q, cf, x) : (! , ! , ! , _ , !); \nPeakingSVFTPT(Q, cf, x) = LPSVF(Q, cf, x) - HPSVF(Q, cf, x); \nBP2SVFTPT(Q, cf, x) = SVFTPT(Q, cf, x) : (! , ! , ! , ! , _); \n  \n// Bandpass Bandwidth SVF \nBPBWSVFTPT(BW, CF, x) = BPSVF(clip(20000, EPS, (CF / BW)), CF, x); \n"},"Posts/Digital-Reverberation---a-tutorial-in-Faust":{"title":"Digital Reverberation - a tutorial in Faust","links":[],"tags":[],"content":"Digital reverberation is a continually relevant and widely discussed topic in the realms of computer music and Digital Signal Processing, as well as electroacoustic music in general. Its applications and studies have involved both commercial and academic sectors. Consequently, over time, a complex history has developed, characterized by numerous ramifications and implications, leading to a proliferation of various methods and implementation topologies. In this study, we will delve into the subject in detail, examining the main existing implementations.\nReverberation\nReverberation is the persistence of sound after it has been produced. It is an acoustic phenomenon related to the reflection of sound waves by an obstacle placed in front of the sound source. Assumptions that determine the perception of a reverberation phenomenon:\n\nThe human ear cannot distinguish two sounds if they are perceived less than 100 milliseconds apart.\nThe speed of sound in the air at 20°C is approximately 340 m/s.\nThe sound source and the listener are in the same location facing the obstacle.\n\nGiven these assumptions, in an open space, reverberation can be discussed when the obstacle is less than 17 meters from the sound source. Indeed, up to this distance, the path of the sound wave from the source to the obstacle and back is less than 34 meters, and therefore the sound takes less than 100 milliseconds to return to the starting point, blending into the listener’s ear with the original sound. If the obstacle is more than 17 meters away from the source, then the delay of the reflected sound compared to the direct sound is more than 100 milliseconds, and the two sounds are therefore distinct. In this case, it is called an echo.\nDuration of Reverberation\nThe factors that influence the duration of reverberation are multiple. The most influential ones are:\n\n\nRoom size\n\nLarger rooms produce longer reverberations.\nSmall rooms produce shorter reverberations.\n\n\n\nMaterials\n\nHard materials like ceramics and plastics reflect sound more.\nSoft materials like wood absorb much more sound.\n\nFor these reasons related to materials, a small room like a bathroom has longer reverberation times than a large wooden room.\n\n\nThe best way to listen to the reverberation of a reverberant space is to produce an impulsive sound; like a clap of hands or a snap of fingers.\nReverberation in Music\nMusic has made extensive use of reverberation for thousands of years. Archaeologists believe that reverberation produced by caves was used in ancient ceremonies. Many cathedrals in Europe have reverberations lasting more than 10 seconds, and the choral music of certain eras worked particularly well by exploiting the reverberation inside these cathedrals. In fact, the reverberation of individual notes overlaps on subsequent notes, transforming a monophonic melody into a polyphonic sound.\nReflections\nA standard room has 6 surfaces:\n\nRight wall\nLeft wall\nFront wall\nBack wall\nCeiling\nFloor\n\nA sound, when produced, bounces off the surfaces and is subsequently heard, producing what are called:\n\nFirst-order reflections\n\nEach of these will produce another 6 echoes: 6 echoes, each bouncing off the 6 surfaces, will produce 36 echoes; these are called:\n\nSecond-order reflections\n\nproducing a total of 42 echoes in a very short period of time, and so on… Of all these echoes, none is perceived individually, but rather their ensemble and dispersion over time are perceived. Reverberation is thus composed of thousands of echoes of the original sound that persist and decay over time.\nArtificial Reverberation Models\nReverberation is artificial when it is not present in the room where the recording is taking place but is instead added later.\n\n\nTape echo\nA particular magnetic tape recorder/player is used, which constantly moves a tape loop inside a mechanism with a fixed recording head and a mobile playback head. The signal recorded by the first head is read by the second and mixed with the original, generating the effect. These devices are bulky and heavy. Like in any tape recording, there is background noise similar to hiss, significantly higher than that produced with digital technologies.\n\n\nSpring reverb\nThe signal is passed, through a transducer, through a metal spiral (the spring). At the other end of the spring, a transducer equivalent to the first one reintroduces the signal into the amplification circuit, mixing it with the original. The signal taken from the second transducer is slightly delayed compared to the one applied to the first, creating the reverberation effect in the listener’s ear.\n\n\nChamber reverb\nFollowing the spring reverb model, in a box acoustically isolated from the outside, a curved tube is inserted to create the longest possible path. At one end of the tube is placed a small loudspeaker, while at the other end there is a microphone. The sound emitted by the loudspeaker will take some time to travel the entire tube and reach the microphone, thus generating the necessary delay. The signal taken from the microphone will be fed back into the mixing console, mixed with the original.\n\n\nPlate reverb\nSimilar to spring reverb, but with a large metal plate instead of the spring. It has two transducers attached to its surface and works in a similar way, although its quality is significantly higher.\n\n\nDigital Reverbs\nThey are produced by a computer or dedicated DSP integrated circuits.\nThere are integrated circuits on the market that include A/D and D/A converters,\nmemories, and timing circuits.\nAn acoustic signal is transduced and converted into numbers that enter memories.\nIn fact, the bytes are “scrolled” from one bank to the next until the last one is reached.\nThe digital signal taken from the last memory is then reconverted into analog and mixed\nwith the original signal, obtaining the reverberation effect;\nthe farther the read point from the write point, the longer the echo time will be.\nThe size of these read and write memories is called delay line, and it is expressed in samples.\nThe large capacity of RAM memories allows achieving delays\nof several seconds and therefore smoothly transition from reverb to echo.\nThe strategy used afterwards is to feed back the output of the delay line by adding it to the input,\nthus creating a feedback circuit.\nAll this process is done because modern computers are very powerful,\nbut they are not yet powerful enough to generate all the reflections\nheard in a large room, one by one.\nRather, the goal of creating digital reverbs is to implement models and strategies\nto replicate the impression of the reverberation of a room.\nThe replication process has generated in the history of digital reverbs true and proper typical sounds different from each other\nwhich can be implemented and preferred by musicians for aesthetic reasons.\nDigital Reverb in FAUST\nExperiments and algorithms of digital reverb models in the FAUST language (GRAME)\nDelay Lines in Faust\nDelay lines in Faust are divided into the following categories:\nmem - indicates a single sample delay\n@ - indicates a number (e.g., 44100) of variable delay samples\nx’- x indicates any input and: ’ a sample delay, ”(2), etc.\nrdtable - indicates a read-only table\nrwtable - indicates a read and write table.\nThrough delay lines,\nwe can create a Dirac impulse, which represents\nour minimum unit, namely the single sample\nby putting a number 1 and subtracting the same value from it\nbut doing it at a delayed sample.\nExample:\n// import Standard Faust library \n// github.com/grame-cncm/faustlibraries/ \nimport(&quot;stdfaust.lib&quot;); \n  \n// Dirac Impulse with delay lines - Impulse at Compile Time \ndirac = 1 - 1&#039;; \nprocess = dirac, dirac; \nSome Methods for Implementing Recursive Circuits in the Faust Language\nWe will illustrate 3 main methods:\n\n\nWriting the code line with internal recursion:\nin this way the tilde ~ operator sends the signal\noutput to itself, to the first available input\ncreating a feedback circuit.\nOne way to force the operator to point to a certain point\nin the code, is to put parentheses (), in this way ~\nwill point to the input before the parenthesis.\n\n\nA second method consists of using with{} .\nYou can define a function in which are passed\nthe various arguments of the function that control\nthe parameters of the code,\nand say that that function is equal to\nexit from the with with ~ _\nExample:\n    function_with(argument1, argument2) = out_with ~ _\n     with{  \n      section1 = _ * argument1;\n      section2 = argument1 * argument2;\n      out_with = section2;\n      };\n    \n      where out_with ~ _ returns to itself.\n\n\nMoreover, with in Faust allows declaring variables\nthat are not pointed to from outside the code but only\nfrom the belonging function; in this case\nthe function to which with belongs is “function_with”.\n\n\nA third method is to use the letrec environment.\nwith this method we can write a signal\nrecursively, similar to how\nrecurrence equations are written.\n\n\nExample:\n// import Standard Faust library  \n// github.com/grame-cncm/faustlibraries/  \nimport(&quot;stdfaust.lib&quot;); \n  \n// letrec function \nlowpass(cf, x) = y \n// letrec definition \n     letrec { \n         &#039;y = b0 * x - a1 * y; \n     } \n     // inside the letrec function \n     with { \n         b0 = 1 + a1; \n         a1 = exp(-w(cf)) * -1; \n         w(f) = 2 * ma.PI * f / ma.SR; \n     }; \n  \n // Output of the letrec function \n process = lowpass(100, no.noise) &lt;: si.bus(2); \nConversion of Milliseconds to Samples and Vice Versa\nConversion from Milliseconds to Samples\nFunction for Conversion from Milliseconds to Samples:\nwe input the time in milliseconds,\nand the function gives us the value in samples.\nFor example, if we have a sampling frequency\nof 48,000 samples per second,\nit means that 1000ms (1 second) is represented\nby 48,000 parts, and therefore a single unit\nof time like 1 ms. Corresponds digitally to 48 samples.\nFor this reason, we divide the sampling frequency\nby 1000ms, resulting in a total number of samples\nthat corresponds to 1 ms. in the digital world at\na certain sampling frequency.\nAnd then we multiply the result of this operation\nby the total number of milliseconds we want to obtain as\na representation in samples.\nIf we multiply *10. For example, we will get\n480 samples at a sampling frequency\nof 48,000 samples per second.\nConversion from Samples to Milliseconds\nFunction for Conversion from Samples to Milliseconds:\nwe input a total number of samples,\nof which we need to know the overall duration\nin milliseconds based on our sampling frequency.\nWe know that a sampling frequency\ncorresponds to a set of values that express\ntogether the duration of 1 second (1000 ms).\nIt means, for example,\nthat at a sampling frequency of 48,000\nsamples per second,\n1000 milliseconds are represented by 48,000 parts.\nSo if we divide our 1000ms. /\ninto the 48,000 parts which are the samples of our system,\nwe would get the duration in milliseconds of a single sample\nat that sampling frequency,\nin this case therefore:\n1000 / 48,000 = 0.02ms.\nAnd so the duration in milliseconds of a single sample at 48,000\nsamples per second, is 0.02 milliseconds.\nIf we multiply the obtained number *\na total number of samples, we will get the time in milliseconds\nof those samples for that sampling frequency used.\nObviously, as can be deduced from the considerations,\nas the sampling frequency increases,\nthe temporal duration of a single sample decreases,\nand thus a greater definition.\nPhase Alignment of Feedback\nIn the digital domain, the feedback of a\ndelay line, when applied, costs by default one sample delay.\nFeedback = 1 Sample\nAt the moment I decide therefore to put\ninside the feedback a number\nof delay samples,\nwe can take for example 10 samples\nin our delay line, it means that,\nThe direct signal will come out for delay samples at:\ninput in the delay signal ⇒ output from the delay 10samp\n1st Feedback:\noutput from the delay at 10samp + 1 feedback =\ninput in the delay 11samp ⇒ output from the delay 21samp\n2nd Feedback:\noutput from the delay at 21samp + 1 feedback =\ninput in the delay 22samp ⇒ output from the delay 32samp\n3rd Feedback:\noutput from the delay at 32samp + 1 feedback =\ninput in the delay 33samp ⇒ output from the delay 43samp\nand so on…\nwe can therefore notice immediately that we will not have\nthe correct delay value required inside the same,\nbecause of the sample delay that occurs at the moment\nwhen I decide to create a feedback circuit.\nif we use the method of subtracting one sample from the delay line,\nwe will have this result:\ninput in the delay signal ⇒ -1, output from the delay 9samp\n1st Feedback:\noutput from the delay at 9samp + 1 feedback =\ninput in the delay 10samp ⇒ -1, output from the delay 19samp\n2nd Feedback:\noutput from the delay at 19samp + 1 feedback =\ninput in the delay 20samp ⇒ -1, output from the delay 29samp\n3rd Feedback:\noutput from the delay at 29samp + 1 feedback =\ninput in the delay 30samp ⇒ -1, output from the delay 39samp\nand so on…\nwe can therefore notice that with this method,\ncompared to the previous one we will have as input to the delay line\nalways the number of delay samples required.\nBut we notice that from the first output of the delayed signal\nsubtracting -1 we have one sample delay\nless than we would like.\nTo realign everything, we just need to add one sample delay\nto the overall output of the circuit, thus having from the first output:\ninput in the delay signal ⇒ -1, output from the delay 9samp +1 = 10out\n1st Feedback:\noutput from the delay at 9samp + 1 feedback =\ninput in the delay 10samp ⇒ -1, output from the delay 19samp +1 = 20out\nand so on…\nLet’s proceed with an implementation:\n// import Standard Faust library  \n// github.com/grame-cncm/faustlibraries/  \nimport(&quot;stdfaust.lib&quot;); \n  \nsampdel = ma.SR;  \n// sample rate - ma.SR \n  \nprocess =   _ :  \n             // input signal goes in \n             +~ @(sampdel -1) *(0.8)  \n             // delay line with feedback: +~ \n             : mem \n             // output goes to a single sample delay \n             &lt;: si.bus(2); \nT60 Decay Calculation\nThe term “T60” in the context of digital reverberation refers to the reverberation time. The reverberation time is a measure of the duration for which sound persists in a space after the sound source has stopped. It indicates how quickly the sound energy decreases over time.\nThe T60 value represents the time it takes for the sound level to decrease by 60 decibels (dB) compared to its initial value. In other words, it is the time taken for the sound energy to decay by 60 dB. A long T60 indicates prolonged reverberation, while a short T60 indicates shorter reverberation.\nThe formula below uses the relationship between the T60 decay time and the number of filter samples to calculate the amplification gain necessary. The result of the calculation is a linear value ranging from 0 to 1, representing the amplification to be applied to the filter feedback.\nInsert the following arguments into the function:\n\n\nThe value in samples of the filter\nyou are using for the delay.\n\n\nThe decay value in T60\n(decay time of 60 dB in seconds)\n\n\n= GET as output from the function,\nthe value to be passed as amplification\nto the filter feedback to achieve\nthe desired T60 decay time\n\n\n// T60 DECAY TIME from Milliseconds\n// (ms, T60) = ms delay of the filter, seconds we want for t60 decay\nt60_ms(ms, t60) = pow(0.001, (ms / 1000) / t60);\n \n// formula 2 \n// (samps,seconds) = give: samples of the filter, seconds we want for t60 decay \ndect60(samps,seconds) = 1/(10^((3*(((1000 / ma.SR)*samps)/1000))/seconds)); \nDigital Filters\nONEZERO FILTER (1st Order FIR)\n_ represents the input signal, (_ denotes the signal)\nit is then split into two parallel paths &lt;:\none delayed by one sample _’ (’ denotes one sample delay)\nand one without delay , _ (, denotes transition to the second path)\nthey are then summed into a single signal :&gt; _ ;\nthe delayed signal has a feedforward amplitude control * feedforward\nthere is a general amplitude control * outgain\non the output function onezeroout\n // import Standard Faust library \n // github.com/grame-cncm/faustlibraries/ \n import(&quot;stdfaust.lib&quot;); \n  \n  \n // (G) = G=give amplitude 0-1(open-close) to the delayed signal \n ozf(G) = _ &lt;: ((_ : mem * G), _) :&gt; +; \n  \n // out \n process = ozf(0.1); \nONEPOLE FILTER (1st Order IIR)\n+~ is the summation, and the feedback\nof the arguments inside parentheses ()\n_ represents the input signal, (_ denotes the signal)\ndelayed by one sample _ (automatically in the feedback)\nwhich enters : into the gain control of the feedback * 1-feedback\nthe same feedback controls the input amplification\nof the signal not injected into the feedback\nthere is a general amplitude control * outgain\non the output function onezeroout\n // import Standard Faust library \n // github.com/grame-cncm/faustlibraries/ \n import(&quot;stdfaust.lib&quot;); \n  \n // (G)  = give amplitude 1-0 (open-close) for the lowpass cut \n // (CF) = Frequency Cut in HZ \n OPF(CF,x) = OPFFBcircuit ~ _  \n     with{ \n         g(x) = x / (1.0 + x); \n         G = tan(CF * ma.PI / ma.SR):g; \n         OPFFBcircuit(y) = x*G+(y*(1-G)); \n         }; \n  \n process = OPF(20000) &lt;: si.bus(2); \nONEPOLE Topology Preserving Transforms (TPT)\nTPT version of the One-Pole Filter by Vadim Zavalishin\nreference: (by Will Pirkle)\nwww.willpirkle.com/Downloads/AN-4VirtualAnalogFilters.2.0.pdf\n // import Standard Faust library \n // github.com/grame-cncm/faustlibraries/ \n import(&quot;stdfaust.lib&quot;); \n  \n OnepoleTPT(CF,x) = circuit ~ _ : ! , _ \n     with { \n         g = tan(CF * ma.PI / ma.SR); \n         G = g / (1.0 + g); \n         circuit(sig) = u , lp \n             with { \n                 v = (x - sig) * G; \n                 u = v + lp; \n                 lp = v + sig; \n             }; \n     }; \n  \n // out \n process = OnepoleTPT(100); \nFEEDFORWARD COMB FILTER (Nth Order FIR)\n_ represents the input signal, (_ denotes the signal)\nit is then split into two parallel paths &lt;:\none delayed by @(delaysamples) samples\n(thus value to be passed externally)\nand one without delay , _ (, denotes transition to the second path)\nthey are then summed into a single signal :&gt; _ ;\nIn the feedback, one sample of delay is already present by default,\nhence delaysamples-1.\nthe delayed signal has a feedforward amplitude control * feedforward\nthere is a general amplitude control * outgain\non the output function onezeroout\n// import Standard Faust library \n// github.com/grame-cncm/faustlibraries/ \nimport(&quot;stdfaust.lib&quot;); \n \n// (t,g) = delay time in samples, filter gain 0-1 \nffcf(t, g, x) = (x@(t) * g), x :&gt; +; \nprocess = _ * .1 : ffcf(100, 1); \nFEEDBACK COMB FILTER (Nth Order IIR)\n+~ is the summation, and the feedback\nof the arguments inside parentheses ()\n_ represents the input signal, (_ denotes the signal)\ndelayed by @(delaysamples) samples\n(thus value to be passed externally)\nwhich enters : into the gain control of the feedback * feedback\nIn the feedback, one sample of delay is already present by default,\nhence delaysamples-1.\nthere is a general amplitude control * outgain\non the output function combfeedbout\n // import Standard Faust library \n // github.com/grame-cncm/faustlibraries/ \n import(&quot;stdfaust.lib&quot;); \n  \n // Feedback Comb Filter. FBComb(Del,G,signal)  \n // (Del, G) = DEL=delay time in samples. G=feedback gain 0-1 \n fbcf(del, g, x) = loop ~ _  \n     with { \n         loop(y) = x + y@(del - 1) * g; \n     }; \n  \n process = _ * .1 : fbcf(4480, .9); \nLowpass FEEDBACK COMB FILTER (Nth Order IIR)\nsimilar to the comb filter, but within the feedback,\nfollowing the feedback enters the signal : into the onepole.\nThe onepole is a lowpass where the cutoff\nfrequency can be controlled between 0. and 1.\nIn the feedback, one sample of delay is already present by default,\nhence delaysamples-1.\n // import Standard Faust library \n // github.com/grame-cncm/faustlibraries/ \n import(&quot;stdfaust.lib&quot;); \n  \n // LPFBC(Del, FCut) = give: delay samps, -feedback gain 0-1-, lowpass Freq.Cut HZ \n lpfbcf(del, cf, x) = loop ~ _ : !, _ \n     with { \n         onepole(CF, x) = loop ~ _  \n             with{ \n                 g(x) = x / (1.0 + x); \n                 G = tan(CF * ma.PI / ma.SR):g; \n                 loop(y) = x * G + (y * (1 - G)); \n             }; \n         loop(y) = x + y@(del - 1) &lt;: onepole(cf), _; \n     }; \n process = _ * .1 : lpfbcf(2000, 10000); \nALLPASS FILTER\nfrom the sum (+ transitions : to a cable _ and a split &lt;:\nthen @delay and gain, in feedback ~ to the initial sum.\nfiltergain controls the amplitude of the two gain states,\nwhich in the filter are the same value but positive and negative,\none side *-filtergain and one side *+filtergain.\nIn the feedback, one sample of delay is already present by default,\nhence delaysamples-1.\nTo maintain the delay threshold of the value delaysamples,\na mem delay (of the subtracted sample) is added\nat the end\n // Allpass\n // (t,g) = give: delay in samples, feedback gain 0-1\n apf(t, g) =    _ : (+ : _ &lt;: @ (t  - 1), * (- g)) ~ * (g) : mem, _ : + : _;\n process = _ * .1 &lt;: apf(100, .5); \nModulated ALLPASS FILTER\n// delay modulated : mod = mod source +/- 1, t = del in samps, tMod = mod in samps\ndelaymod(mod, t, tMod) = de.fdelay(tMax, modIndx)\nwith{\n    tMax = t + tMod;\n    modIndx = t + mod * tMod;\n};\n \n// modulated Allpass filter\napfMod(mod, t, tMod, g) = _ : (+ : _ &lt;: delaymod(mod, t - 1, tMod), * (- g)) ~ * (g) : mem, _ : + : _;\n \nprocess = apfMod(os.osc(0.10), 19200, 100, 0.7)\nTopologies and Design of Digital Reverbs\nChamberlin Reverb\nThe Chamberlin Reverb is named after Hal Chamberlin, a pioneer in digital sound processing. This reverberation model was first introduced in his seminal book, Musical Applications of Microprocessors (1979).\nAt its core, the Chamberlin Reverb uses a network of all-pass filters (APF) to create a dense and natural-sounding reverberation effect.\nThe model is particularly effective at simulating small acoustic spaces, such as rooms or chambers, and is designed with simplicity in mind, making it computationally efficient. This efficiency made it suitable for the early digital processors with limited resources.\n// Chamberlin Reverb\nchamberlinReverb = ap3ch &lt;: apout1ch, apout2ch\nwith {\n    ap3ch = apf(msasamps(49.6), 0.75) : apf(msasamps(34.75), 0.72) : apf(msasamps(24.18), 0.691);\n    apout1ch = apf(msasamps(17.85), 0.649) : apf(msasamps(10.98), 0.662);\n    apout2ch = apf(msasamps(18.01), 0.646) : apf(msasamps(10.82), 0.666);\n};\nprocess = chamberlinReverb;\nChamberlin Reverb with Decay T60\nThis version includes a decay time T60 control in the comb-allpass filters, representing the time required for the signal to decay by 60 dB.\n// Chamberlin Reverb with T60 Decay\nchamberlinDecay(seconds) = ap3ch &lt;: apout1ch, apout2ch\nwith {\n    ap3ch = apf(msasamps(49.6), t60_ms(49.6, seconds)) : \n            apf(msasamps(34.75), t60_ms(34.75, seconds)) : \n            apf(msasamps(24.18), t60_ms(24.18, seconds));\n    apout1ch = apf(msasamps(17.85), t60_ms(17.85, seconds)) : \n               apf(msasamps(10.98), t60_ms(10.98, seconds));\n    apout2ch = apf(msasamps(18.01), t60_ms(18.01, seconds)) : \n               apf(msasamps(10.82), t60_ms(10.82, seconds));\n};\nprocess = chamberlinDecay(10);\nSchroeder-Chowning SATREV Reverberator\nThe Schroeder-Chowning SATREV Reverberator is a landmark in the history of algorithmic reverb design, based on the design proposed by Manfred Schroeder and refined by John Chowning, this model combines 4 parallel comb filters with 3 serial all-pass filters (drawn from a 1971 MUS10 software listing).\n// Schroeder-Chowning SATREV Reverberator\nsatreverb = _ * 0.2 &lt;: fbcfSchroeder(901, 0.805), \n    fbcfSchroeder(778, 0.827), fbcfSchroeder(1011, 0.783), \n    fbcfSchroeder(1123, 0.764) :&gt; apf(125, 0.7) : \n    apf(42, 0.7) : apf(12, 0.7) &lt;: _ , _ * -1;\nprocess = satreverb;\nSchroeder Samson Box Reverberator\nIn October 1977, CCRMA took delivery of the Systems Concepts Digital Synthesizer, affectionately known as the “Samson Box,” named after its designer Peter Samson.\nThis reverberator developed for this system, which remains known as JCREV, builds upon the earlier reverberation models by Schroeder but expanding on them with improvements that catered to more complex, real-time audio processing requirements.\nThis model includes 3 serial all-pass filters and 4 parallel comb filters.\n// Schroeder Samson Box Reverberator\njcreverb = _ * 0.06 : apf(347, 0.7) : apf(113, 0.7) : \n    apf(37, 0.7) &lt;: fbcfSchroeder(1601, 0.802), fbcfSchroeder(1867, 0.733), \n    fbcfSchroeder(2053, 0.753), fbcfSchroeder(2251, 0.733) : \n    mix_mtx\nwith {\n    mix_mtx = _,_,_,_ &lt;: psum, - psum, asum, - asum : _,_,_,_;\n    psum = _,_,_,_ :&gt; _;\n    asum = *(-1), _, *(-1), _ :&gt; _;\n};\nprocess = jcreverb;\nMoorer Reverb\nJames A. Moorer’s 1979 design for digital reverberation was one of the earliest to build upon the work of Manfred R. Schroeder, refining and expanding on his ideas in significant ways. Moorer’s design, as outlined in his seminal paper “About This Reverberation Business”, introduced crucial improvements to digital reverb algorithms that continue to influence modern reverberation models.\nA key innovation in Moorer’s approach was the use of a tapped delay line to simulate early reflections—an important feature in the perception of acoustic space. The early reflections, rather than the later reverberant tail, play a more prominent role in how we perceive the size and shape of an environment. The tapped delay line in Moorer’s model could be adjusted with specific delay times and gain structures to approximate the reflections of an actual acoustic space, such as a concert hall. In his article, Moorer provides a 19-tap delay line based on a geometric simulation of the Boston Symphony Hall. He omits the first tap, which has a delay time of 0 and a gain of 1, as it represents the original dry signal.\nAdditionally, Moorer enhanced his reverb model by incorporating a first-order low-pass filter in the feedback loop of the six comb filters. This filter simulates the absorption effects of air, which are influenced by factors such as humidity, temperature, the frequency of sound, and the distance from the sound source. Moorer discusses how atmospheric conditions affect the intensity of sound as it travels, and this low-pass filter helped account for the natural damping of higher frequencies over distance.\nThis combination of early reflections through a tapped delay line and the low-pass feedback filters for air absorption marked a significant step forward in creating more realistic digital reverberation, and Moorer’s work laid the foundation for many of the reverberation algorithms in use today.\n// Moorer Reverb\nmoorerReverb = _ * 0.1 : earlyReflections &lt;: combSection + _\nwith {\n    earlyReflections =  _ &lt;: \n        (_ @ sasamps(0.0043)) * 0.841,\n        (_ @ sasamps(0.0215)) * 0.504,\n        (_ @ sasamps(0.0225)) * 0.491,\n        (_ @ sasamps(0.0268)) * 0.379,\n        (_ @ sasamps(0.0270)) * 0.380,\n        (_ @ sasamps(0.0298)) * 0.346,\n        (_ @ sasamps(0.0458)) * 0.289,\n        (_ @ sasamps(0.0485)) * 0.272,\n        (_ @ sasamps(0.0572)) * 0.192,\n        (_ @ sasamps(0.0587)) * 0.193,\n        (_ @ sasamps(0.0595)) * 0.217,\n        (_ @ sasamps(0.0612)) * 0.181,\n        (_ @ sasamps(0.0707)) * 0.180,\n        (_ @ sasamps(0.0708)) * 0.181,\n        (_ @ sasamps(0.0726)) * 0.176,\n        (_ @ sasamps(0.0741)) * 0.142,\n        (_ @ sasamps(0.0753)) * 0.167,\n        (_ @ sasamps(0.0797)) * 0.134 :&gt; _;\n \n    combSection = _ &lt;: \n        lbcf(sasamps(0.040), 0.95, 0.5),\n        lbcf(sasamps(0.041), 0.95, 0.5),\n        lbcf(sasamps(0.043), 0.95, 0.5),\n        lbcf(sasamps(0.055), 0.95, 0.5),\n        lbcf(sasamps(0.059), 0.95, 0.5),\n        lbcf(sasamps(0.061), 0.95, 0.5) :&gt; _ :\n        apf(sasamps(0.007), -0.09683) @ sasamps(0.0017);\n};\nprocess = moorerReverb;\nFreeverb\nA more recently developed Schroeder/Moorer Reverberation Simulation\nis Freeverb — a public domain C++ program by\nJezar at Dreampoint used extensively in the\nfree-software world.\nIt uses four Schroeder allpasses in series and\neight parallel Schroeder-Moorer filtered-feedback\ncomb-filters for each audio channel,\nand is said to be especially well tuned.\nfreeverb = _ * 0.1 : combSection : allpassSection\nwith {\n    combSection = _ &lt;: \n    // 1557 samples at 44100 = ms 35.3061218\n    lbcf(msasamps(35.3061218), 0.84, 0.2),\n    // 1617 samples at 44100 = ms 36.6666679\n    lbcf(msasamps(36.6666679), 0.84, 0.2),\n    // 1491 samples at 44100 = ms 33.8095245\n    lbcf(msasamps(33.8095245), 0.84, 0.2),\n    // 1422 samples at 44100 = ms 32.2448997\n    lbcf(msasamps(32.2448997), 0.84, 0.2),\n    // 1277 samples at 44100 = ms 28.9569168\n    lbcf(msasamps(28.9569168), 0.84, 0.2),\n    // 1356 samples at 44100 = ms 30.7482986\n    lbcf(msasamps(30.7482986), 0.84, 0.2),\n    // 1188 samples at 44100 = ms 26.9387760\n    lbcf(msasamps(26.9387760), 0.84, 0.2),\n    // 1116 samples at 44100 = ms 25.3061218\n    lbcf(msasamps(25.3061218), 0.84, 0.2) :&gt; _;\n \n    allpassSection = \n    // 225 samples at 44100 = ms 5.1020408\n    apf(msasamps(5.10204080), -0.5) :\n    // 556 samples at 44100 = ms 12.6077099\n    apf(msasamps(12.6077099), -0.5) :\n    // 441 samples at 44100 = ms 10.0000000\n    apf(msasamps(10.0000000), -0.5) :\n    // 341 samples at 44100 = ms 7.7324262\n    apf(msasamps(7.73242620), -0.5);\n};\nprocess = freeverb;\nFeedback Delay Network (FDN)\nThe first ideas originate from Michael Gerzon’s\nStudio Sound reverb articles from 1971 and 1972.\nLater, in 1982, Stautner and Puckette introduced a\nmultichannel reverberation algorithm in their paper\n“Designing Multichannel Reverberators.”\nThe algorithm, called the Feedback Delay Network (FDN),\naims to simulate the behavior of reflections\nwithin a room by using only a series of parallel\ncomb filters with interconnected feedback paths.\nBelow is a 4x4 example of the general design they proposed.\nfdnLossless = (inputPath : delaysPath : hadamardPath : normHadamard) ~ \nsi.bus(4) : delCompensation\nwith{\n    t60(msDel, t60) = pow(0.001, msDel / t60);\n    inputPath = ro.interleave(4, 2) : par(i, 4, (_, _) :&gt; _);\n    delay(ms) = _ @ (msasamps(ms) - 1);\n    delaysPath = delay(68), delay(77), delay(90), delay(99);\n    hadamardPath = hadamard(4);\n    normHadamard = par(i, 4, _ * (1.0 / sqrt(4)));\n    delCompensation = par(i, 4, mem);\n};\n//process = fdnLossless :&gt; par(i, 2, _ / 2);\n \nfdn = (inputPath : opPath : delaysPath : hadamardPath : normHadamard : decay) ~ \nsi.bus(4) : delCompensation\nwith{\n    t60(msDel, t60) = pow(0.001, msDel / t60);\n    inputPath = ro.interleave(4, 2) : par(i, 4, (_, _) :&gt; _);\n    opPath = par(i, 4, op(0.4));\n    delay(ms) = _ @ (msasamps(ms) - 1);\n    delaysPath = delay(68), delay(77), delay(90), delay(99);\n    hadamardPath = hadamard(4);\n    normHadamard = par(i, 4, _ * (1.0 / sqrt(4)));\n    decay = _ * t60_ms(68, 1), _ * t60_ms(77, 1), \n            _ * t60_ms(90, 1), _ * t60_ms(99, 1);\n    delCompensation = par(i, 4, mem);\n};\nprocess = fdn :&gt; par(i, 2, _ / 2);\nKeith Barr Allpass Loop\nKeith Barr was one of the co-founders of MXR,\nback in 1973. After MXR, he founded Alesis.\nMost recently, he designed the FV-1 chip for Spin Semiconductor.\nHis Allpass Loop Reverb is a simplified yet effective model,\nutilizing a single allpass filter within a feedback loop.\nWhen multiple delays and all pass filters are placed into a loop,\nsound injected into the loop will recirculate,\nand the density of any impulse will increase as the signal\npasses successively through the allpass filters.\nThe result, after a short period of time,\nwill be a wash of sound, completely diffused\nas a natural reverb tail.\nThe reverb can usually have a mono input\n(as from a single source),\nbut benefits from a stereo output which gives\nthe listener a more full, surrounding reverberant image.\nHere a Faust porting of: Reverb 1 program from the Spin Semiconductor FV-1 internal ROM\nkb_rom_rev1(rt, damp, L, R) = aploop\nwith{\n// input allpass sections\napSec(0) = apf(adaptSR(32768, 156), 0.5) : apf(adaptSR(32768, 223), 0.5) : apf(adaptSR(32768, 332), 0.5) : apf(adaptSR(32768, 548), 0.5);\napSec(1) = apf(adaptSR(32768, 186), 0.5) : apf(adaptSR(32768, 253), 0.5) : apf(adaptSR(32768, 302), 0.5) : apf(adaptSR(32768, 498), 0.5);\n \n// allpass loop sections\nloopSec(0) = _ @ (adaptSR(32768, 4568) - 1) : _ * rt : _ + (L : apSec(0)) : apfMod(os.osc(0.5), adaptSR(32768, 1251), adaptSR(32768, 20), 0.6) : apf(adaptSR(32768, 1751), 0.6) : op(damp) : op(- 0.05);\nloopSec(1) = _ @ adaptSR(32768, 5859) : _ * rt : apf(adaptSR(32768, 1443), 0.6) : apf(adaptSR(32768, 1343), 0.6) : op(damp) : op(- 0.05);\nloopSec(2) = _ @ adaptSR(32768, 4145) : _ * rt : _ + (R : apSec(1)) : apfMod(os.osc(0.5), adaptSR(32768, 1582), adaptSR(32768, 20), 0.6) : apf(adaptSR(32768, 1981), 0.6) : op(damp) : op(- 0.05);\nloopSec(3) = _ @ adaptSR(32768, 3476) : _ * rt : apf(adaptSR(32768, 1274), 0.6) : apf(adaptSR(32768, 1382), 0.6) : op(damp) : op(- 0.05);\n \n// output delay taps\noutTaps = ((_ * 1.5 @ adaptSR(32768, 2630), _ * 1.2 @ adaptSR(32768, 1943), _ * 1.0 @ adaptSR(32768, 3200), _ * 0.8 @ adaptSR(32768, 4016)) :&gt; +),\n((_ * 1.0 @ adaptSR(32768, 2420), _ * 0.8 @ adaptSR(32768, 2631), _ * 1.5 @ adaptSR(32768, 1163), _ * 1.2 @ adaptSR(32768, 3330)) :&gt; +);\n \n// complete allpass loop\naploop = (_ : loopSec(0) &lt;: ((loopSec(1) &lt;: ((_ : loopSec(2) &lt;: loopSec(3), _), _)), _)) ~ _ : ro.cross(4) &lt;: outTaps; \n};\nprocess = kb_rom_rev1(0.95, 0.5); \nHere another Reverb Model based on the Keith Barr Allpass Loop Reverb.\nA Corey Kereliuk’s implementation of the Reverb.\nck_kbVerb(apfG, krt) = si.bus(2) : mix(ma.PI/2) : * (0.5), * (0.5) : procLeft, procRight : si.bus(2)\nwith{\t \n    // stereo input mix\n    mix(theta) = si.bus(2) &lt;: (*(c), *(-s), *(s), *(c)) : (+, +) : si.bus(2)\n\twith {\n\t\tc = cos(theta);\n\t\ts = sin(theta);\n\t};\n \n    // import prime numbers\n    primes = component(&quot;prime_numbers.dsp&quot;).primes;\n    // calculation of left and right indexes\n    ind_left(i)  = 100 + 10 * pow(2, i) : int;\n    ind_right(i) = 100 + 11 * pow(2, i) : int;\n \n    // allpass single section\n    section((n1, n2)) = apf(n1, - apfG) : apf(n2, - apfG) : _ @ int(0.75 * (n1 + n2));\n \n    // chain and ring functions\n    allpass_chain(((n1, n2), ns), x) = _ : section((n1, n2)) &lt;: R(x, ns), _\n    with {\n    \tR(x, ((n1, n2), ns)) = _,x : + : section((n1, n2)) &lt;: R(x, ns), _;\n    \tR(x, (n1, n2)) = _,x : + : section((n1, n2));\n    };\n    procMono(feedfwd_delays, feedback_delays, feedback_gain, x) = x : \n    (+ : allpass_chain(feedfwd_delays, x)) ~ (_,x : + : section(feedback_delays) : \n    *(feedback_gain)) :&gt; _;\n    // left reverb\n\tfeedfwd_delays_left = par(i, 5, (ba.take((ind_left(i)), primes), ba.take((ind_left(i+1)), primes)));\n\tfeedback_delays_left = (ba.take(100, primes), ba.take(101, primes));\n\tprocLeft = procMono(feedfwd_delays_left, feedback_delays_left, krt);\n\t// right reverb\n\tfeedfwd_delays_right = par(i, 4, (ba.take((ind_right(i)), primes), ba.take((ind_right(i+1)), primes)));\n\tfeedback_delays_right = (ba.take(97, primes), ba.take(99, primes));\n\tprocRight = procMono(feedfwd_delays_right, feedback_delays_right, krt);\n};\nprocess = ck_kbVerb(0.7, 0.5);\nJames Dattorro and the Lexicon 480L Topology: A Landmark in Reverb Design\nIn his groundbreaking paper published in the Journal of the Audio Engineering Society, Vol. 45, No. 9, September 1997, James Dattorro opened up the design secrets behind the allpass loop reverbs, offering detailed insights into a reverb architecture that would shape the future of digital reverb technology.\nWhereas earlier papers, such as Gardner’s, hinted at concepts that had been circulating privately within the music technology industry, Dattorro’s paper fully exposed the inner workings of allpass loop reverbs. He introduced a specific allpass loop reverb in great detail, including all the delay lengths and coefficients, which he described as being “in the style of [Lexicon’s] Griesinger.” This paper effectively served as a Rosetta Stone for reverb design, offering a clear and practical understanding of the mechanisms that drive reverb effects. Many modern reverb plugins and built-in synth reverbs have directly recreated the “Dattorro” reverb, underscoring the paper’s enduring influence in the field.\nOne of the paper’s key contributions was Dattorro’s exploration of the single loop feedback system, which was central to the Lexicon 480L’s reverb design. This architecture, which Dattorro helped reveal, is simpler yet more effective in simulating natural reverbs, providing dense and realistic sound with minimal complexity. The Lexicon 480L’s feedback structure, initially shrouded in secrecy, was described in Dattorro’s work with full transparency, as the company had granted him permission to detail their proprietary system. This was a crucial moment in the advancement of reverb design, as it opened up new possibilities for digital reverberation.\ngreisingerReverb(decay, damp) = (si.bus(2) :&gt; _ * (1 / 2) : predelay : op(damp) : apfsec) &lt;: si.bus(2) : (ro.interleave(2, 2) : (par(i, 2, (_, _) :&gt; + : loopsec(i)) : ro.crossNM(4, 1), si.bus(3))) ~ si.bus(2) : (si.block(2), si.bus(6)) : routing\nwith{\n    predelay = _ @ msasamps(30);\n \n    apfsec = apf(msasamps(4.771), 0.75) : apf(msasamps(3.595), 0.75) :\n        apf(msasamps(12.73), 0.625) : apf(msasamps(9.307), 0.625);\n \n    loopsec(0) = apfMod(os.osc(0.10), msasamps(30.51), msasamps(4), 0.7) : \n        _ @ msasamps(141.69) : (_ &lt;: _, _) : (op(damp), _) : \n        (apf(msasamps(89.24), 0.5) &lt;: _, _), _ : \n        (_ @ (msasamps(106.28) - 1) &lt;: _, mem), _, _ :  \n        (_ * decay, _, _, _) : (_, ro.cross(3));\n \n    loopsec(1) = apfMod(os.osc(0.07), msasamps(22.58), msasamps(4), 0.7) : \n        _ @ msasamps(149.62) : (_ &lt;: _, _) : (op(damp), _) : \n        (apf(msasamps(60.48), 0.5) &lt;: _, _), _ : \n        (_ @ (msasamps(125.00) - 1) &lt;: _, mem), _, _ :  \n        (_ * decay, _, _, _) : (_, ro.cross(3));\n \n    routing(dA0, ap0, dB0, dA1, ap1, dB1) = \n        ((dA0 @ msasamps(8.90), dA0 @ msasamps(99.8), ap0 @ msasamps(64.2), dB0 @ msasamps(67),\n          dA1 @ msasamps(66.8), ap1 @ msasamps(6.3), dB1 @ msasamps(35.8),  0) :&gt; +),\n        ((dA0 @ msasamps(70.8), ap0 @ msasamps(11.2), dB0 @ msasamps(4.1), dA1 @ msasamps(11.8), \n          dA1 @ msasamps(121.7), ap1 @ msasamps(41.2), dB1 @ msasamps(89.7), 0) :&gt; +);\n};\nprocess = greisingerReverb(0.8, 0.4); \nReferences\n\nManfred Schroeder, “Natural Sounding Artificial Reverb,” 1962.\nMichael Gerzon, “Synthetic Stereo Reverberation,” 1971.\nJames (Andy) Moorer, “About This Reverberation Business,” 1979\nChristopher Moore, “Time-Modulated Delay System and Improved Reverberation Using Same,” 1979.\nJohn Stautner and Miller Puckette, “Designing Multichannel Reverberators,” 1982.\nJon Dattorro, “Effect Design - Part 1: Reverberator and Other Filters,” 1997.\nJean-Marc Jot, “Efficient models for reverberation and distance rendering in computer music and virtual audio reality,” 1997.\nD. Rochesso, “Reverberation,” DAFX - Digital Audio Effects, Udo Zölzer, 2002.\n\nTopologies\n\nManfred Schroeder propone l’applicazione di una rete di allpass e comb filters.\nJames Moorer implementa un filtro lowpass all’interno della retroazione dei comb.\nChristopher Moore propone linee di ritardo modulate nel tempo e uscite Multi-tap da modelli delle early relfection.\nWilliam Martens e Gary Kendall propongono delle early reflection spazializzate.\nMichael Gerzon, John Stautner &amp; Miller Puckette propongono le Feedback Delay Network (mixer a matrice per i feedback).\nDavid Griesinger propone un singolo Loop di Feedback utilizzando ritardi e filtri allpass.\n\nMain References\nIntroduction to Digital Filters:\nWith Audio Applications.\nbooks by Julius O. Smith III.\nLinks to the series by Smith:\n\nMathematics of the Discrete Fourier Transform (DFT)\nIntroduction to Digital Filters\nPhysical Audio Signal Processing\nSpectral Audio Signal Processing\nCCRMA by J.Smith ccrma.stanford.edu/~jos/fp/ su DSP Related Free DSP Books\n\nTOM ERBE - UC SAN DIEGO - REVERB TOPOLOGIES AND DESIGN tre.ucsd.edu/wordpress/wp-content/uploads/2018/10/reverbtopo.pdf\nARTIFICIAL REVERBERATION: su DSPRELATED Artificial Reverberation | Physical Audio Signal Processing\nCorey Kereliuk - Building a Reverb Plugin in Faust\nKeith Barr’s reverb architecture Building a Reverb Plugin in Faust\nSpin Semiconductor DSP Basics Spin Semiconductor - DSP Basics Spin Semiconductor Audio Effects Spin Semiconductor - Effects\nfreeverb3vst - Reverb Algorithms Tips freeverb3vst.osdn.jp/tips/reverb.shtml\nHistory of allpass loop / “ring” reverbs History of allpass loop / “ring” reverbs? - Spin Semiconductor\nMusical Applications of Microprocessors (The Hayden microcomputer series) sites.music.columbia.edu/cmc/courses/g6610/fall2016/week8/Musical_Applications_of_Microprocessors-Charmberlin.pdf\nAcustica_Riverbero - Alfredo Ardia Appunti: acustica_Riverbero\nAlgorithmic Reverbs: The Moorer Design Algorithmic Reverbs: The Moorer Design | flyingSand\nDattorro Convex Optimization of a Reverberator Dattorro Convex Optimization of a Reverberator - Wikimization\nprimes under 10.000 www.matematika.it/public/allegati/34/Numeri_primi_minori_di_10000_1_3.pdf"},"Posts/Exploring-Pseudo-Random-and-Stochastic-Signals-in-Digital-Sound-Synthesis":{"title":"Exploring Pseudo-Random and Stochastic Signals in Digital Sound Synthesis","links":[],"tags":[],"content":"Random and stochastic signals in synthesis can be useful for implementing time-varying oscillators and/or control signals. A common issue in digital synthesizers and audio effects is that the sounds often differ significantly from those produced in the physical world, due to the precise, time-invariant nature of signal generation in the digital domain.\nIn computers, time-varying details that occur unpredictably in the physics of sound must be carefully sequenced, often to the point of exhausting the resources of the computer (and the programmer).\nThis problem has existed since the early days of computer music. Indeed, we can think of the first examples of research in this field, such as those conducted by Max Mathews and his colleagues at Bell Labs, who studied the possibilities of sound control using nonlinear signals and algorithms in the early MUSIC-N family synthesis languages. Some examples include low-frequency noise generators such as RAN and RAH, which generate pseudo-random signals for controlling sound parameters like frequency, amplitude, etc.\nUsing nonlinear signals in sound synthesis and control can thus be an effective way to generate sounds that are closer to natural ones compared to those generated through more standard digital synthesis techniques, using more computationally efficient methods. Here, I will implement circuits in the Faust programming language (GRAME) to discretely represent some pseudo-random and stochastic models useful for generating control signals.\nWhite Noise Generator\nThe first fundamental building block for working with random numbers is the pseudo-random number generator, also known in the Digital Signal Processing (DSP) domain as digital white noise. When a random stream of numbers is generated and reproduced at the sample level, the resulting sound is typical of white noise. White noise generators have been used in the field of computer music since its beginning. We can trace their utilization back to even Max Mathew’s 1963 article The Digital Computer as a Musical Instrument, the first known paper on computer music.\nIn general, a random number generator provides an N-bit binary number every time it is called. If these conditions are truly met, each bit or any subset of the bits in the numbers should also be random. However, no algorithmic random number generator completely meets all of these criteria. In fact, most random number generation algorithms are numerical functions that accept their previous output as input and generate a new output.\nThe initial input used when the generator is started is called the seed, and it can usually be any number except zero. If the same seed number is used on two different occasions, the series of numbers generated will also be the same.\nSince the output numbers are integers with a finite number of bits, it is obvious that at some point in the sequence the seed will appear again. From this point forward, the sequence repeats itself.\nAn efficient random number generator will generate all or nearly all of the 2N different numbers that can be represented by an N-bit word before repeating.\nLinear Congruential Generator\nOne of the most popular random number algorithms is the linear congruential method. The first model is attributed to the Lehmer random number generator (named after D. H. Lehmer), sometimes also referred to as the Park-Miller random number generator (after Stephen K. Park and Keith W. Miller). This is a type of linear congruential generator (LCG) that operates in the multiplicative group of integers modulo N.\nThe basic function is: R_{\\text{new}} = (A \\times R_{\\text{old}} + C) \\mod M\nwhere A and C are carefully chosen constants, and M is the largest possible number plus one for the chosen word length. The generator is completely specified by giving values for A, C, and the word length. For any given word length, there are values for A and C (besides the trivial ones, A = 1 and C = 1) that will give M values before repeating.\nIn Faust, a typical linear congruential generator following this method can be written as follows:\nimport(&quot;stdfaust.lib&quot;);\n\n// Pseudo-random noise with linear congruential generator (LCG)\nnoise(initSeed) = lcg ~ _ : (_ / m)\nwith{\n a = 18446744073709551557; c = 12345; m = 2 ^ 31; \nlcg(seed) = ((a * seed + c) + (initSeed - initSeed&#039;) % m);\n};\nprocess = noise(1212);\n\nThis algorithm will generate a new random value on every sample, corresponding to the sample rate of the system.\nHow the LCG Works:\nInitialization:\n   - The generator starts with an initial seed (initSeed) that serves as the starting value for the sequence. The quality of randomness depends heavily on this seed.\nRecurrence Relation:\n   - The generator calculates each new random value in seed\n   - Here:\n     - A: Is the multiplier.\n     - C: Is the increment.\n     - M: Is the modulus, which determines the range of possible output values.\nFeedback:\n   - The output of the lcg function is fed back into itself through the feedback operator (~ in FAUST), allowing it to generate a sequence of pseudo-random numbers.\nScaling:\n   - The result is divided by M (_ / m) to normalize the output to the range [0, 1].\nConstants in the Code:\n   - a: A large, carefully chosen multiplier to ensure good randomness.\n   - c: A small constant increment, often chosen to avoid patterns in the generated numbers.\n   - m: The modulus, chosen as a power of two (here, 2^{31}), which is common for computational efficiency.\nMultiple Outputs\nIt is also possible to generate multiple outputs from the same linear congruential generator by adding an internal sequential operation seqN that repeats the LCG process in series and takes multiple taps. Here’s an example of how you can create multiple outputs:\nimport(&quot;stdfaust.lib&quot;);\n\n// Noise - Linear Congruential Generator - Multiple Outputs\nmultinoise(N, initSeed) = ((_ + (initSeed - initSeed&#039;) : \n    seqN(N, (_ * a + c) % m )) ~ _ : par(i, N, _ / m))\nwith{\n    // LCG constants\n    a = 18446744073709551557; c = 12345; m = 2 ^ 31; \n    // Sequential operations\n    seqN(N, OP) = _ &lt;: seq(i, N, (OP &lt;: _, _), \n        si.bus(i + 1)) : (_, !, si.bus(N - 1), !);\n};\nprocess = multinoise(4, 1212);\n\nLow frequency Noise Generator\nSince in Faust every function runs at the single sample level, our linear congruential generator will generate a new number at every sample. For this reason, if we want to use a noise generator as a low-frequency oscillator for control signals, we need to hold the values at slower rate intervals.\nFor this purpose, the first thing we need to do is build a sample-and-hold module that can hold a signal when triggered.\nIn Faust, we can write a sample-and-hold function as follows:\nimport(&quot;stdfaust.lib&quot;);\n\n// a classic sample and hold\nsah(x, t) = selector(t, _, x) ~ _\nwith{\n    // binary selector\n    selector(sel, x, y) = x * (1 - sel) + y * (sel);\n};\n\nHow sah Works:\nInitial State:\n\nThe feedback loop (~ _) initializes the memory (_) to zero (or undefined, depending on implementation).\n\nSampling:\n\nWhen t (the trigger signal) becomes 1, the selector picks the value of x (the input signal) and stores it in the feedback loop (_).\n\nHolding:\n\nWhen t is 0, the selector picks the previously stored value from _, effectively holding the last sampled value.\n\nThe feedback (~) allows the output to retain and “remember” the last sampled value. Without it, the function would only output the input directly without holding any value.\nNow that we have our SAH module, we need a clock function that can generate triggers at regular intervals. For this purpose, we need triggers that last only one sample. In fact, if we use this sample and hold function with a bandwidth larger than a single sample, the gate of the input signal will remain open depending on the duration of the band before the output is stored in our feedback circuit.\nWe can write a single-sample trigger as follows:\nimport(&quot;stdfaust.lib&quot;);\n\n// Synchronous pulse train in HZ\nmetro(ms) = phasor0(1000 / max(1, ms)) : derivate + dirac\nwith{\n    // phasor that start from 0\n    phasor0(f) = (_ &lt;: _ + f, _) ~ _ % ma.SR : (!, _ / ma.SR);\n    // Dirac Impulse at Compile Time\n    dirac = 1 - (1 : mem);\n    // first derivate\n    derivate(x) = x &lt; x&#039;;\n};\nprocess = metro(100);\n\nHow the Synchronous Pulse Train (metro) Works:\nThe metro function generates a pulse train with a specified frequency (given in milliseconds).\nMain Function:\n\nmetro(ms) takes an input in milliseconds (ms) to define the pulse interval.\nIt converts the interval in milliseconds to a frequency in Hz using: 1000 / max(1, ms) This ensures the frequency is always positive and at least 1 ms, avoiding divisions by 0.\n\nPhasor Generation:\nphasor0(f) = (_ &lt;: _ + f, _) ~ _ % ma.SR : (!, _ / ma.SR);\nCreates a repeating ramp signal (phasor) that oscillates between 0 and 1.\n• _ &lt;: _ + f Increments the current phase value by f (frequency).\n• ~ _ Uses feedback to store the current phase value across iterations.\n• % ma.SR Resets the phase to 0 when it reaches the Sample Rate, creating a looping behavior.\n• _ / ma.SR Normalizes the ramp signal to a range of [0, 1] dividing the output by Sample Rate.\nDerivative Detection:\nderivate(x) = x &lt; x&#039;; Detects when the phasor value resets to 0 by comparing the current value (x) with its previous value at 1 sample delay Z^{-1} = &#039;.\nDirac Impulse:\ndirac = 1 - (1 : mem); (mem and &#039; are the same) Generates a single impulse at compile time, ensuring an initial pulse is present.\nThe pulse train is generated by combining the output of the derivative (derivate) with the Dirac impulse: metro(ms) = phasor0(1000 / max(1, ms)) : derivate + dirac;\nwhere:\n• phasor0 creates the ramp signal.\n• derivate detects when the ramp resets.\n• dirac ensures an initial pulse is present.\n• The combination produces a series of synchronized 1 sample pulses.\nNow that our modules are complete, we can connect them together to sample the noise input at a low sampling rate, building the low-frequency noise generator as follows:\nprocess = noise(1212), metro(100) : sah;\n\nOr by putting everything together in a single function:\nimport(&quot;stdfaust.lib&quot;);\n\n// noise sampled with a classic sample and hold\nsahNoise(seed, f) = selector(pulseTrain, _, noise(seed)) ~ _\nwith{\n    // Pseudo-random noise with linear congruential generator (LCG)\n    noise(initSeed) = lcg ~ _ : (_ / m)\n    with{\n        a = 18446744073709551557; c = 12345; m = 2 ^ 31; \n        lcg(seed) = ((a * seed + c) + (initSeed - initSeed&#039;) % m);\n    };\n    // binary selector\n    selector(sel, x, y) = x * (1 - sel) + y * (sel);\n    // Dirac Impulse at Compile Time\n    dirac = 1 - (1 : mem);\n    derivate(x) = x &lt; x&#039;;\n    phasor0 = (_ &lt;: _ + f, _) ~  _ % ma.SR : (!, _ / ma.SR);\n    pulseTrain = phasor0 : derivate + dirac;\n};\nprocess = sahNoise(1212, 100);\n\nThis will sample random values every 100 milliseconds.\nIf we decide to use the same code and trigger the SAH manually,\nwe obtain a random number generator.\nA new random number is generated each time the user clicks the GUI button.\nimport(&quot;stdfaust.lib&quot;);\n\n// random number generator\nrandom(range, seed, trigger) = ((noise(seed) : abs), dirac(trigger)) : \n    sah * range\nwith{\n    // transform a constant to 1 sample trigger\n    dirac(x) = (x - x&#039;) &gt; 0;\n    // Pseudo-random noise with linear congruential generator (LCG)\n    noise(initSeed) = lcg ~ _ : (_ / m)\n    with{\n        a = 18446744073709551557; c = 12345; m = 2 ^ 31; \n        lcg(seed) = ((a * seed + c) + (initSeed - initSeed&#039;) % m);\n    };  \n    // a classic sample and hold\n    sah(x, t) = selector(t, _, x) ~ _\n    with{\n        // binary selector\n        selector(sel, x, y) = x * (1 - sel) + y * (sel);\n    };\n};\nprocess = random(100, 1212, button(&quot;trigger&quot;));\n\nwhere abs ensures only positive values by applying the absolute value, range is a multiplication factor that determines the output range, extending it beyond [0, 1] to [0, range], and dirac(x) = (x - x&#039;) &gt; 0; transforms a signal with a bandwidth larger than a single sample into a single-sample impulse.\nAsynchronous Low frequency Noise Generator\nWe now have a low frequency noise generator, but the values are output at a synchronous clock rate. This means that while the sequence of values is unpredictable, the timing of updates remains consistent.\nIf we want to make our noise generator more complex, we can apply the principles we’ve learned so far to create an asynchronous clock for our low-frequency noise by mixing these elements together.\nWhat we aim to achieve now is the generation of a clock with asynchronous timing, so that the output values from the sample and hold can change at unpredictable moments.\nThe following Faust code implements a random impulse generator, where the impulses occur at irregular intervals based on a pseudo-random number generator. The intervals are constrained to a range between ms1 and ms2, specified in milliseconds.\n// random impulse generator / ms1 &amp; ms2 = range\nrandometro(seed, ms1, ms2) = randomtrigger\nwith{\n    // Pseudo-random noise with linear congruential generator (LCG)\n    noise(initSeed) = lcg ~ _ : (_ / m)\n    with{\n        a = 18446744073709551557; c = 12345; m = 2 ^ 31; \n        lcg(seed) = ((a * seed + c) + (initSeed - initSeed&#039;) % m);\n    };\n    // Dirac Impulse at Compile Time\n    dirac = 1 - (1 : mem);\n    derivate(x) = x &lt; x&#039;;\n    phasor0(f) = (_ &lt;: _ + f, _) ~  _ % ma.SR : (!, _ / ma.SR);\n    pulseTrain(f) = phasor0(f) : derivate;\n    // a classic sample and hold\n    sah(t, x) = selector(t, _, x) ~ _\n    with{\n        // binary selector\n        selector(sel, x, y) = x * (1 - sel) + y * (sel);\n    };\n    msMin = min((1000 / max(1, ms1)), (1000 / max(1, ms2)));\n    msMax = max((1000 / max(1, ms1)), (1000 / max(1, ms2)));\n    randomtrigger = ((_ + dirac), abs(noise(seed)) * (msMax - msMin) + msMin : \n        sah : pulseTrain) ~ _;\n};\n//process = randometro(1212, 100, 4000), randometro(1234, 100, 4000);\n\nThe function randometro(seed, ms1, ms2) takes as its input a seed value for the LCG and ms1, ms2 as the bounds of the random interval range, given in milliseconds.\nmsMin = min((1000 / max(1, ms1)), (1000 / max(1, ms2)));\nmsMax = max((1000 / max(1, ms1)), (1000 / max(1, ms2)));\n\nThis converts the input intervals ms1 and ms2 (in milliseconds) into corresponding frequencies in Hz.\nThe variables msMin andmsMax represent the lower and upper bounds, ensuring consistent interval limits derived from ms1 and ms2.\nBeyond the functions we have already discussed, the core of the random impulse train is defined as:\nrandomtrigger = ((_ + dirac), abs(noise(seed)) * (msMax - msMin) + msMin : \n    sah : pulseTrain) ~ _;\n\nThe function generates a random interval using noise(seed), scaled to the range [msMin, msMax].\nHere, msMin serves as the base frequency offset, while msMax scales the seed to adjust the range of the output values. The term (msMax - msMin) ensures the maximum range does not exceed the intended limit, as msMin is added as a base offset.\nNext, the sah function is used to sample and hold the random value, ensuring it remains constant during the specified interval.\nFinally, the pulseTrain function takes the random value as its frequency, varying it over time based on the newly generated random number. This output is fed back into the sah function, which triggers the next random value and consequently alters the frequency, creating a dynamic and unpredictable sequence.\nWe now have a random impulse generator that we can use as a clock source for the low-frequency noise generator, making it operate at asynchronous time intervals. This can be used as a non-linear control signal.\nBelow is the complete code that brings it all together:\nimport(&quot;stdfaust.lib&quot;);\n\n// SAH noise at random intervals / ms1 &amp; ms2 = range\nsahNoiserandom(seed, ms1, ms2) = selector(randometro, _, noise(seed)) ~ _\nwith{\n    // Pseudo-random noise with linear congruential generator (LCG)\n    noise(initSeed) = lcg ~ _ : (_ / m)\n    with{\n        a = 18446744073709551557; c = 12345; m = 2 ^ 31; \n        lcg(seed) = ((a * seed + c) + (initSeed - initSeed&#039;) % m);\n    };\n    // binary selector\n    selector(sel, x, y) = x * (1 - sel) + y * (sel);\n    // random impulse generator / ms1 &amp; ms2 = range\n    randometro = randomtrigger\n    with{\n        // Dirac Impulse at Compile Time\n        dirac = 1 - (1 : mem);\n        derivate(x) = x &lt; x&#039;;\n        phasor0(f) = (_ &lt;: _ + f, _) ~  _ % ma.SR : (!, _ / ma.SR);\n        pulseTrain(f) = phasor0(f) : derivate;\n        // a classic sample and hold\n        sah(t, x) = selector(t, _, x) ~ _\n        with{\n            // binary selector\n            selector(sel, x, y) = x * (1 - sel) + y * (sel);\n        };\n        msMin = min((1000 / max(1, ms1)), (1000 / max(1, ms2)));\n        msMax = max((1000 / max(1, ms1)), (1000 / max(1, ms2)));\n        randomtrigger = ((_ + dirac), abs(noise(seed * 2)) * (msMax - msMin) + \n            msMin : sah : pulseTrain) ~ _;\n    };\n};\nprocess = sahNoiserandom(1212, 100, 4000);\n\nStochastic Signals\nIn Digital Signal Processing (DSP), the concept of stochastic processes is often used to describe signals that evolve unpredictably over time. While random signals (such as noise) can be unpredictable, stochastic processes are defined by probabilistic models that describe the likelihood of different outcomes, making their behavior dynamic but not entirely predetermined.\nFor example, random walks and Brownian motion are both types of stochastic processes commonly used to model natural, physical randomness, and they lead to outputs that feel more connected to real-world phenomena.\nStochastic processes are useful in applications where randomness and gradual changes are required, such as in Brownian motion, fractal-based noise, and Markov chains. These processes introduce correlations between successive values, which is particularly useful for modeling behaviors that evolve smoothly rather than in abrupt, discontinuous jumps.\nA stochastic process in fact refers to a system that is nondeterministic or unpredictable. It evolves in a way that can’t be precisely predicted, though it is governed by probabilistic rules. These processes are defined by their probabilistic models, which describe the likelihood of various outcomes over time, making them dynamic with behavior that is not predetermined.\nOn the other hand, random typically refers to something that is unrecognizable or not following any identifiable pattern. Random signals evolve in time in an unpredictable manner, and their individual values cannot be predicted with certainty. However as we observe with pseudo-random generators, the average properties of random signals are deterministic. Since total unpredictability cannot be computed, the terms “stochastic” and “random” can sometimes be used interchangeably.\nA case of study of the Random Walk : the Drunk object from Max Msp\nOne of the simplest stochastic processes is the random walk, a term first introduced by Karl Pearson in 1905. The random walk is the formalization of the idea of taking successive steps in random directions, and it is the simplest Markov process, whose most well-known mathematical representation is the Norbert Wiener process. A Wiener process, also known as Brownian motion, is a Gaussian stochastic process in continuous time with independent increments. It is used to model Brownian motion itself as well as various random phenomena observed in applied mathematics, finance, and physics.\nThe term “Brownian motion” specifically refers to the erratic motion of particles small enough (with diameters on the order of a micrometer) to be unaffected by gravity, present in fluids or gaseous suspensions (such as smoke), and observable under a microscope. The phenomenon was discovered in the early 19th century by the Scottish botanist Robert Brown and was later modeled in 1905 by the German theoretical physicist Albert Einstein.\nIn the Max MSP programming environment, an example of Brownian motion for control signals can be found in the object drunk.\nThe drunk walk model is a stochastic process that nominally follows the path of a drunk person who has just left a bar. At each step, he randomly chooses to move either to the left or to the right, without knowing where he came from or where he is going. After the first step, his next move is chosen randomly, either left or right, and this pattern continues. In the mathematical model, the drunk never sobers up, and an interesting feature of this process is that the drunk tends to return to his starting point over time.\nI attempted and succeeded in porting this model to Faust.\nBelow is the Faust code that implements the random walk process.\nimport(&quot;stdfaust.lib&quot;);\n\n// random walk generator : variable steps and max value\ndrunk(seed, maxvalue, stepsize, trigger) = noise(seed), (trigger : dirac) : \n    sah * (abs(stepsize) + 1) : int * (trigger : dirac) : + ~ _ : \n        foldInt(abs(maxvalue))\nwith{\n    // transform a constant to 1 sample trigger\n    dirac(x) = (x - x&#039;) &gt; 0;\n    // pseudo-random noise with linear congruential generator (LCG)\n    noise(initSeed) = lcg ~ _ : (_ / m)\n    with{\n        a = 18446744073709551557; c = 12345; m = 2 ^ 31; \n        lcg(seed) = ((a * seed + c) + (initSeed - initSeed&#039;) % m);\n    };\n    // a classic sample and hold\n    sah(x, t) = selector(t, _, x) ~ _\n    with{\n        // binary selector\n        selector(sel, x, y) = x * (1 - sel) + y * (sel);\n    };\n    // fold at max Int value and 0\n    foldInt(maxv, x) = maxv - abs((abs(x) % (2 * maxv)) - maxv);\n};\nprocess = (os.phasor(1, 10) - 0.1 &lt; 0.0) : drunk(1212, 100, 10);\n\nIn this code, at every trigger input, the sample and hold noise provides an integer value between a base of 1 and a maximum value, similar to how we implement the random impulse generator. However, the key difference is that at each step, the value is held inside the integrator (+ ~ _), and at successive steps, a sum or difference is performed between the value stored in the integrator and the new value generated.\nTo achieve this, we need to ensure that when a new number is generated by the sah, it lasts only one sample (int * (trigger : dirac)). If we don’t implement this, another operation will be automatically performed on the next sample, causing unintended results.\nFinally, the foldInt object: foldInt(maxv, x) = maxv - abs((abs(x) % (2 * maxv)) - maxv); ensures that only values within the range of maxvalue are output. If the range is exceeded, a foldover operation is performed on the signal, wrapping the value back into the defined range.\nAn important aspect of creating time-varying control signals is to obtain a smooth transition between every sample. In fact, a random walk signal like the one generated by the drunk object, at the sample level in Faust, creates discontinuities in the signal. These discontinuities can lead to issues such as aliasing, or worse, an overall lack of definition in the behaviors used to control a carrier signal due to the poor temporal consistency of the signal.\nAn alternative way to program a random walk in Faust in response to these problems could be simpler than this last one. By changing the direction of the signal at every sample, we can impose a condition on the noise generator to produce only binary values in the range of [-1, 1]. To avoid discontinuities, we can use integration techniques such as linear interpolation or filters to smooth the signal.\nrandomWalk(seed, speed, smooth, trigger) = binaryNoise(seed) / ma.SR : + ~ _ : _ * speed : wavefolding : fi.lowpass(1, 1 / smooth)\nwith{\n    // transform a constant to 1 sample trigger\n    dirac(x) = (x - x&#039;) &gt; 0;\n    // a classic sample and hold\n    sah(x, t) = selector(t, _, x) ~ _\n    with{\n        // binary selector\n        selector(sel, x, y) = x * (1 - sel) + y * (sel);\n    };\n    // pseudo-random binary noise with linear congruential generator (LCG)\n    binaryNoise(initSeed) = lcg ~ _ : (_ / m) : condition\n    with{\n        a = 18446744073709551557; c = 12345; m = 2 ^ 31; \n        lcg(seed) = ((a * seed + c) + (initSeed - initSeed&#039;) % m);\n        condition = _ &lt;: (_ &gt; 0.0) + (_ &lt;= 0.0) * - 1;\n    };\n    // WAVEFOLDING\n    wavefolding = intreset &lt;: trifunctionpos,trifunctionneg :&gt; + : _ * 2\n    with{\n        intreset(x)= x-int(x);\n        triconditionpos(x) = (x &lt;  0.5) * (x) + ((x &gt;  0.5) * ((x * -1) +1));\n        trifunctionpos(x) = (x &gt; 0) * (x) : triconditionpos;\n        triconditionneg(x) = (x &gt; -0.5) * (x) + ((x &lt; -0.5) * ((x * -1) -1));\n        trifunctionneg(x) = (x &lt; 0) * (x) : triconditionneg;\n    };\n};\nprocess = (os.phasor(1, 100) - 0.1 &lt; 0.0) : randomWalk(1212, 10, 2); \n\nThis last code is an example of how one can generate a non-linear, fully functioning control signal from a stochastic model like the random walk, or from other generators to obtain complex behaviors. We can address the resolution of this kind of problem by focusing on continuity, since from the RAN object in Music V. In his book on computer music (Mathews, The Technology of Computer Music), Max Mathews explains how, in the random number generator, he achieved a continuous function using linear interpolation methods.\nThe calibration of non-linear signal processing is an art in itself, involving a range of functional models beyond the one described here. It requires studying and refining the response of control signals and is closely tied to the type of analysis and behavior a composer or programmer seeks to achieve in their algorithm. Given the importance of this topic, it will require further focus, which I will explore in more depth in future posts."},"Studies/PhD/PhD":{"title":"PhD","links":[],"tags":[],"content":""},"Studies/SMERM/SMERM":{"title":"SMERM","links":["Studies/SMERM/Analisi_della_partitura_di_Sequenza_I_di.pdf","Studies/SMERM/Analisi_di_Curtis_Roads_Eleventh_Vortex.pdf","Studies/SMERM/Breve_analisi_di_Anton_Webern_Tre_piccol.pdf","Studies/SMERM/Analisi_acustiche_di_un_Bedroom_Home_Stu.pdf","Studies/SMERM/La_Riverberazione_Digitale.pdf","Studies/SMERM/Oscillatori_Virtuali_Caotici_Sintesi_del.pdf","Studies/SMERM/Realizzazione_degli_Oscillatori_del_sint.pdf","Studies/SMERM/Preamplificatore_per_Arduino_con_IC_LM38.pdf","Studies/SMERM/Virtual_Patchable_Modular_Controller_con.pdf","Studies/SMERM/Le_Prime_Figure_Tecniche_nella_Musica_El.pdf","Studies/SMERM/Sistemi_Complessi_Adattivi_per_la_perfor.pdf"],"tags":[],"content":"Scuola di Musica Elettronica di RoMa\nMaterials and Notes written while I was studying Electronic Music at the Conservatory in Rome (2015 - 2023).\nThe materials are in Italian.\nEssays:\n\nAnalisi_della_partitura_di_Sequenza_I_di.pdf\nAnalisi_di_Curtis_Roads_Eleventh_Vortex.pdf\nBreve_analisi_di_Anton_Webern_Tre_piccol.pdf\nAnalisi_acustiche_di_un_Bedroom_Home_Stu.pdf\nLa_Riverberazione_Digitale.pdf\nOscillatori_Virtuali_Caotici_Sintesi_del.pdf\nRealizzazione_degli_Oscillatori_del_sint.pdf\nPreamplificatore_per_Arduino_con_IC_LM38.pdf\nVirtual_Patchable_Modular_Controller_con.pdf\n\nBachelor’s degree Thesis:\n\nLe_Prime_Figure_Tecniche_nella_Musica_El.pdf\n\nMaster’s degree Thesis:\n\nSistemi_Complessi_Adattivi_per_la_perfor.pdf\n"},"index":{"title":"Website","links":["Blog","Biography","CV","Compositions","Contact","Links"],"tags":[],"content":"Welcome\n\nI’m Luca Spanedda. My musical practice explores the relationship between humans, cybernetic technologies, and acoustic spaces.\n\nVisit my Blog for posts about Computer Music and related reflections.\nCheck out my Biography and CV for more information about me.\nIn Compositions, you can find details about my works, scores, excerpts, and performances.\nIf you want to reach out, my contact details are in Contact.\n\n\nLinks\n\nGithub\nSoundcloud\nInstagram\nYouTube\nAcademia\n\n"}}